{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29340cf2",
   "metadata": {},
   "source": [
    "### 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94150f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from model.Normalization import *\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    # transforms.Normalize((0,),(12.3,))\n",
    "])\n",
    "# transform=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.RFID_Dataset import RFID_Dataset\n",
    "\n",
    "# 训练集\n",
    "train_dataset=RFID_Dataset(\n",
    "    r\"data\\RFID\\dataset\\all\",\n",
    "    # r\"data\\RFID\\dataset\\train\",\n",
    "    T=32,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    ")\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.RFID_Dataset import RFID_Dataset\n",
    "\n",
    "# 测试集\n",
    "test_dataset=RFID_Dataset(\n",
    "    # r\"data\\RFID\\dataset\\eval\",\n",
    "    r\"./output/improve_v1\",\n",
    "    T=32,\n",
    "    step=1,\n",
    "    # transform=transform,\n",
    ")\n",
    "print(f\"测试集的数据个数: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.FeatureUtils import *\n",
    "\n",
    "train_input,_=train_dataset[:]\n",
    "test_input,_=test_dataset[:]\n",
    "\n",
    "# 降维\n",
    "\n",
    "pca = get_pca_model(train_input, target=2)\n",
    "train_output = use_pca_model(pca, train_input)\n",
    "test_output = use_pca_model(pca, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独的PCA降维\n",
    "\n",
    "train_output=pca_reduce(train_input)\n",
    "test_output=pca_reduce(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独TSNE降维\n",
    "\n",
    "train_output=tsne_reduce(train_input)\n",
    "test_output=tsne_reduce(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制图像\n",
    "\n",
    "from utils.DataUtils.Visualization import plot_classes_scatter\n",
    "\n",
    "plot_classes_scatter(train_output, train_dataset.labels,title=\"Train Data\")\n",
    "plot_classes_scatter(test_output, test_dataset.labels,title=\"Test Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据分布对比\n",
    "\n",
    "from utils.DataUtils.Visualization import plot_classes_scatter\n",
    "import numpy as np\n",
    "\n",
    "datas=np.concatenate([train_output,test_output],axis=0)\n",
    "temp_labels=(test_dataset.labels)+3\n",
    "labels=np.concatenate([train_dataset.labels,temp_labels],axis=0)\n",
    "plot_classes_scatter(datas,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78312f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def tensor_to_numpy(tensor):\n",
    "    \"\"\"统一处理不同框架的张量转NumPy\"\"\"\n",
    "    if hasattr(tensor, \"asnumpy\"):  # MindSpore张量\n",
    "        return tensor.asnumpy()\n",
    "    elif hasattr(tensor, \"numpy\"):  # PyTorch张量\n",
    "        return tensor.detach().cpu().numpy()\n",
    "    return np.array(tensor)\n",
    "\n",
    "\n",
    "def plot_tensor_density(\n",
    "    data,\n",
    "    labels=None,\n",
    "    colors=None,\n",
    "    title=\"Tensor Density Plot\",\n",
    "    xlabel=\"Value\",\n",
    "    ylabel=\"Density\",\n",
    "    bandwidth=0.5,\n",
    "    sample_axis=None,\n",
    "    max_slices=12,  # 新增：最大允许绘制的切片数\n",
    "    verbose=True,  # 是否显示警告信息\n",
    "    save_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    支持高阶张量的密度图绘制（带维度长度限制）\n",
    "\n",
    "    新增参数:\n",
    "    max_slices (int): 允许绘制的最大切片数（超过时自动抽样或跳过）\n",
    "    verbose (bool): 是否提示维度长度警告\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    datasets = []\n",
    "    auto_labels = []\n",
    "\n",
    "    # 处理输入数据\n",
    "    if not isinstance(data, (list, tuple)):\n",
    "        data = [data]\n",
    "\n",
    "    # 步骤1：展平数据并处理sample_axis\n",
    "    for tensor in data:\n",
    "        arr = tensor_to_numpy(tensor)\n",
    "        if sample_axis is not None:\n",
    "            # 获取目标维度长度\n",
    "            dim_length = arr.shape[sample_axis]\n",
    "\n",
    "            # 跳过超长维度\n",
    "            if dim_length > max_slices:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"Warning: Dimension length {dim_length} exceeds max_slices={max_slices}. \"\n",
    "                        f\"Skipping this tensor's sample_axis={sample_axis}\"\n",
    "                    )\n",
    "                continue  # 跳过整个张量的处理\n",
    "\n",
    "            # 正常处理可接受维度\n",
    "            arr = np.moveaxis(arr, sample_axis, 0)  # 将目标轴移到第一维\n",
    "            slices = [x_slice.reshape(-1) for x_slice in arr]  # 每个切片展平为1D\n",
    "            datasets.extend(slices)\n",
    "            auto_labels.extend([f\"Slice {i}\" for i in range(dim_length)])\n",
    "        else:\n",
    "            datasets.append(arr.reshape(-1))\n",
    "\n",
    "    # 步骤2：处理标签和颜色\n",
    "    num_datasets = len(datasets)\n",
    "    if labels is None:\n",
    "        labels = auto_labels\n",
    "    elif len(labels) < num_datasets:\n",
    "        labels += [f\"Slice {i}\" for i in range(len(labels), num_datasets)]\n",
    "\n",
    "    if colors is None:\n",
    "        colors = plt.cm.tab10(range(num_datasets))\n",
    "    elif len(colors) < num_datasets:\n",
    "        colors = list(colors) + [\n",
    "            colors[i % len(colors)] for i in range(len(colors), num_datasets)\n",
    "        ]\n",
    "\n",
    "    # 步骤3：绘制每个切片的KDE\n",
    "    for i, (d, label, color) in enumerate(zip(datasets, labels, colors)):\n",
    "        try:\n",
    "            kde = gaussian_kde(d)\n",
    "            kde.set_bandwidth(bandwidth)\n",
    "            x_range = np.linspace(d.min(), d.max(), 1000)\n",
    "            plt.plot(\n",
    "                x_range, kde(x_range), label=label, color=color, linewidth=2, alpha=0.7\n",
    "            )\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(f\"Skipping {label} due to singular matrix error (insufficient data)\")\n",
    "\n",
    "    # 调整布局\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(fontsize=10, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067290b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datas=train_dataset[:][0]\n",
    "plot_tensor_density(\n",
    "    datas,\n",
    "    sample_axis=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
