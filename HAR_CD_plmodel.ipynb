{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人类活动识别——条件扩散"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "from torchvision import transforms\n",
    "from model.Normalization import RobustNorm\n",
    "from model.Augmentation import NoiseAug\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    RobustNorm(-68.0, 68.0),\n",
    "    # NoiseAug(0.2,std=(0.001))\n",
    "])\n",
    "# transform=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的数据个数: 3871\n",
      "验证集的数据个数: 3871\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "from model.RFID_Dataset import RFID_Dataset\n",
    "\n",
    "train_dir = r\"data\\RFID_multi_628\\dataset\\train\"\n",
    "eval_dir = r\"data\\RFID_multi_628\\dataset\\eval\"\n",
    "\n",
    "train_dataset = RFID_Dataset(\n",
    "    train_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    num_channels=3,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "eval_dataset = RFID_Dataset(\n",
    "    eval_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    num_channels=3,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")\n",
    "print(f\"验证集的数据个数: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\VSCode-code\\python\\RFID_Classify\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=(3, 32, 12)\n",
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "PositionalEncoding-1                        [-1, 64]                    0\n",
      "Linear-2                                    [-1, 64]                4,160\n",
      "SiLU-3                                      [-1, 64]                    0\n",
      "Embedding-4                                 [-1, 64]                  448\n",
      "SiLU-5                                      [-1, 64]                    0\n",
      "Linear-6                                    [-1, 64]                4,160\n",
      "Identity-7                                 [-1, 128]                    0\n",
      "Conv2d-8                            [-1, 64, 32, 12]                1,792\n",
      "GELU-9                              [-1, 64, 32, 12]                    0\n",
      "GroupNorm-10                        [-1, 64, 32, 12]                  128\n",
      "Conv2d-11                           [-1, 64, 32, 12]               36,928\n",
      "GroupNorm-12                        [-1, 64, 32, 12]                  128\n",
      "MaxPool2d-13                         [-1, 64, 16, 6]                    0\n",
      "Conv2d-14                           [-1, 128, 16, 6]                8,320\n",
      "Conv2d-15                           [-1, 128, 16, 6]               73,856\n",
      "GELU-16                             [-1, 128, 16, 6]                    0\n",
      "GroupNorm-17                        [-1, 128, 16, 6]                  256\n",
      "GroupNorm-18                        [-1, 128, 16, 6]                    0\n",
      "Linear-19                                  [-1, 256]               33,024\n",
      "SiLU-20                                    [-1, 256]                    0\n",
      "Conv2d-21                           [-1, 128, 16, 6]              147,584\n",
      "GroupNorm-22                        [-1, 128, 16, 6]                  256\n",
      "Conv2d-23                           [-1, 128, 16, 6]              147,584\n",
      "GELU-24                             [-1, 128, 16, 6]                    0\n",
      "GroupNorm-25                        [-1, 128, 16, 6]                  256\n",
      "Conv2d-26                           [-1, 128, 16, 6]              147,584\n",
      "GroupNorm-27                        [-1, 128, 16, 6]                  256\n",
      "GroupNorm-28                        [-1, 128, 16, 6]                  256\n",
      "MultiheadAttention-29                   [-1, 2, 128]               66,048\n",
      "MaxPool2d-30                         [-1, 128, 8, 3]                    0\n",
      "Conv2d-31                            [-1, 256, 8, 3]               33,024\n",
      "Conv2d-32                            [-1, 256, 8, 3]              295,168\n",
      "GELU-33                              [-1, 256, 8, 3]                    0\n",
      "GroupNorm-34                         [-1, 256, 8, 3]                  512\n",
      "GroupNorm-35                         [-1, 256, 8, 3]                    0\n",
      "Linear-36                                  [-1, 512]               66,048\n",
      "SiLU-37                                    [-1, 512]                    0\n",
      "Conv2d-38                            [-1, 256, 8, 3]              590,080\n",
      "GroupNorm-39                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-40                            [-1, 256, 8, 3]              590,080\n",
      "GELU-41                              [-1, 256, 8, 3]                    0\n",
      "GroupNorm-42                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-43                            [-1, 256, 8, 3]              590,080\n",
      "GroupNorm-44                         [-1, 256, 8, 3]                  512\n",
      "GroupNorm-45                         [-1, 256, 8, 3]                  512\n",
      "MultiheadAttention-46                   [-1, 2, 256]              263,168\n",
      "Conv2d-47                            [-1, 256, 8, 3]              590,080\n",
      "GELU-48                              [-1, 256, 8, 3]                    0\n",
      "GroupNorm-49                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-50                            [-1, 256, 8, 3]              590,080\n",
      "GroupNorm-51                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-52                            [-1, 256, 8, 3]              590,080\n",
      "GELU-53                              [-1, 256, 8, 3]                    0\n",
      "GroupNorm-54                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-55                            [-1, 256, 8, 3]              590,080\n",
      "GroupNorm-56                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-57                            [-1, 256, 8, 3]              590,080\n",
      "GELU-58                              [-1, 256, 8, 3]                    0\n",
      "GroupNorm-59                         [-1, 256, 8, 3]                  512\n",
      "Conv2d-60                            [-1, 256, 8, 3]              590,080\n",
      "GroupNorm-61                         [-1, 256, 8, 3]                  512\n",
      "ConvTranspose2d-62                  [-1, 128, 16, 6]              131,200\n",
      "Conv2d-63                           [-1, 128, 16, 6]               32,896\n",
      "Conv2d-64                           [-1, 128, 16, 6]              295,040\n",
      "GELU-65                             [-1, 128, 16, 6]                    0\n",
      "GroupNorm-66                        [-1, 128, 16, 6]                  256\n",
      "GroupNorm-67                        [-1, 128, 16, 6]                    0\n",
      "Linear-68                                  [-1, 256]               33,024\n",
      "SiLU-69                                    [-1, 256]                    0\n",
      "Conv2d-70                           [-1, 128, 16, 6]              147,584\n",
      "GroupNorm-71                        [-1, 128, 16, 6]                  256\n",
      "Conv2d-72                           [-1, 128, 16, 6]              147,584\n",
      "GELU-73                             [-1, 128, 16, 6]                    0\n",
      "GroupNorm-74                        [-1, 128, 16, 6]                  256\n",
      "Conv2d-75                           [-1, 128, 16, 6]              147,584\n",
      "GroupNorm-76                        [-1, 128, 16, 6]                  256\n",
      "GroupNorm-77                        [-1, 128, 16, 6]                  256\n",
      "MultiheadAttention-78                   [-1, 2, 128]               66,048\n",
      "ConvTranspose2d-79                  [-1, 64, 32, 12]               32,832\n",
      "Conv2d-80                           [-1, 64, 32, 12]                8,256\n",
      "Conv2d-81                           [-1, 64, 32, 12]               73,792\n",
      "GELU-82                             [-1, 64, 32, 12]                    0\n",
      "GroupNorm-83                        [-1, 64, 32, 12]                  128\n",
      "GroupNorm-84                        [-1, 64, 32, 12]                    0\n",
      "Linear-85                                  [-1, 128]               16,512\n",
      "SiLU-86                                    [-1, 128]                    0\n",
      "Conv2d-87                           [-1, 64, 32, 12]               36,928\n",
      "GroupNorm-88                        [-1, 64, 32, 12]                  128\n",
      "Conv2d-89                           [-1, 64, 32, 12]               36,928\n",
      "GELU-90                             [-1, 64, 32, 12]                    0\n",
      "GroupNorm-91                        [-1, 64, 32, 12]                  128\n",
      "Conv2d-92                           [-1, 64, 32, 12]               36,928\n",
      "GroupNorm-93                        [-1, 64, 32, 12]                  128\n",
      "GroupNorm-94                        [-1, 64, 32, 12]                  128\n",
      "MultiheadAttention-95                    [-1, 2, 64]               16,640\n",
      "Conv2d-96                            [-1, 3, 32, 12]                1,731\n",
      "==========================================================================\n",
      "Total params: 7,910,211\n",
      "Trainable params: 7,910,211\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.004395\n",
      "Forward/backward pass size (MB): 7.515625\n",
      "Params size (MB): 30.175060\n",
      "Estimated Total Size (MB): 37.695080\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 模型组网\n",
    "\n",
    "from model.base.UNet import UNet\n",
    "# from model.v1.UNet import UNet\n",
    "# from model.v2.UNet import UNet\n",
    "# from model.v3.UNet import UNet\n",
    "# from model.v4.UNet import UNet\n",
    "\n",
    "from model.BetaScheduler import LinearBetaScheduler\n",
    "from model.CD_Model import CD_Model\n",
    "from model.ModelWorker.CDModelWorker import CDModelWorker\n",
    "import torch\n",
    "from torchkeras import summary\n",
    "\n",
    "input_shape = (3, 32, 12)\n",
    "\n",
    "model = CD_Model(\n",
    "    UNet(\n",
    "        input_shape=input_shape,\n",
    "        init_features=64,\n",
    "        embed_dim=128,\n",
    "        num_heads=1,\n",
    "        num_groups=16,\n",
    "    ),\n",
    "    LinearBetaScheduler(timesteps=1000,beta_end=0.02),\n",
    "    num_classes=6,\n",
    "    embed_dim=128,\n",
    "    enable_guidance=True,\n",
    ")\n",
    "\n",
    "model_worker = CDModelWorker(model)\n",
    "\n",
    "print(f\"{input_shape=}\")\n",
    "\n",
    "time = torch.tensor([0], dtype=torch.long)\n",
    "condition = torch.tensor([0], dtype=torch.long)\n",
    "model_info = summary(model, input_shape=input_shape, time=time, condition=condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型准备\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from model.Loss import *\n",
    "from model.LightningModel.CDPLMpdel import CDPLModel\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "# loss = nn.MSELoss()\n",
    "loss = MinSNRLoss()\n",
    "# loss=SigmoidLoss()\n",
    "\n",
    "pl_model = CDPLModel(\n",
    "    model,\n",
    "    loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# 构建PLTrainer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    min_epochs=5,\n",
    "    logger=True,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(save_weights_only=True),\n",
    "        # EarlyStopping(monitor=\"val/loss\", patience=5),\n",
    "        # EarlyStopping(monitor=\"val/loss\", patience=5,mode=\"min\"),\n",
    "    ],\n",
    "    default_root_dir=\"./output/HAR\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "\n",
    "trainer.fit(\n",
    "    pl_model,\n",
    "    train_loader,\n",
    "    eval_loader,\n",
    ")\n",
    "best_model_path=trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "\n",
    "trainer.validate(\n",
    "    pl_model,\n",
    "    eval_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载PLModel\n",
    "\n",
    "pl_model=CDPLModel.load_from_checkpoint(\n",
    "    best_model_path, \n",
    "    model=model, \n",
    "    criterion=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估-时间步序列\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "sequence=torch.linspace(0, 1000,10+1,dtype=torch.long).tolist()[1:]\n",
    "\n",
    "# eval_loss=nn.MSELoss()\n",
    "eval_loss=ConstantLoss()\n",
    "loss_group=model_worker.evaluate_sequence(\n",
    "    eval_loader=train_loader,\n",
    "    criterion=eval_loss,\n",
    "    time=sequence,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in loss_group.items():\n",
    "    print(f\"{item[0]:4d}: {item[1]:.6f}\")\n",
    "from utils.DataUtils.Visualization import plot_curves,plot_scatter\n",
    "\n",
    "plot_scatter(\n",
    "    loss_group,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model_worker.save('./output/HAR_CD/base/HAR_CD.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model_worker.load('./output/HAR_CD/base/HAR_CD.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 1000/1000 [00:15<00:00, 63.15step/s]\n",
      "Sampling: 100%|██████████| 1000/1000 [00:16<00:00, 60.31step/s]\n",
      "Sampling: 100%|██████████| 1000/1000 [00:16<00:00, 60.47step/s]\n",
      "Sampling: 100%|██████████| 1000/1000 [00:16<00:00, 58.86step/s]\n",
      "Sampling: 100%|██████████| 1000/1000 [00:15<00:00, 64.96step/s]\n",
      "Sampling: 100%|██████████| 1000/1000 [00:15<00:00, 65.16step/s]\n"
     ]
    }
   ],
   "source": [
    "# DDPM采样\n",
    "\n",
    "from model.RFID_Dataset import save_samples\n",
    "\n",
    "batch_count=1\n",
    "num_classes = 6\n",
    "\n",
    "for _ in range(batch_count):\n",
    "    for i in range(num_classes):\n",
    "        # 生成数据\n",
    "        condition = i\n",
    "        datas = model_worker.generate_sample_batch(\n",
    "            10,\n",
    "            condition,\n",
    "            guidance_scale=2,\n",
    "        )\n",
    "\n",
    "        # 保存数据\n",
    "        save_samples(\n",
    "            datas, \n",
    "            output_dir=f\"./output/base/{condition}\",\n",
    "            merge=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDIM采样\n",
    "\n",
    "from model.RFID_Dataset import save_samples\n",
    "\n",
    "num_classes = 6\n",
    "for i in range(num_classes):\n",
    "    # 生成数据\n",
    "    condition = i\n",
    "    cond = torch.full((20,), condition, dtype=torch.long)\n",
    "    datas = model_worker.generate_sample_DDIM(\n",
    "        cond,\n",
    "        time=model_worker.get_linear_sampling_sequence(50),\n",
    "        eta=0.0,\n",
    "        guidance_scale=2,\n",
    "    )\n",
    "\n",
    "    # 保存数据\n",
    "    save_samples(\n",
    "        datas, \n",
    "        output_dir=f\"./output/base_DDIM/{condition}\",\n",
    "        merge=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
