{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人类活动识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.RFID_Dataset import RFID_Dataset\n",
    "from utils.DatasetUtils import DatasetUtils\n",
    "\n",
    "\n",
    "data_utils = DatasetUtils()\n",
    "\n",
    "from torchvision import transforms\n",
    "from model.Normalization import *\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    RobustNorm(-35.0, 35.0)\n",
    "])\n",
    "\n",
    "train_dir = r\"data\\RFID\\dataset\\train\"\n",
    "# train_dir=r\"./output/improve_v2_robust\"\n",
    "eval_dir = r\"data\\RFID\\dataset\\eval\"\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = RFID_Dataset(\n",
    "    train_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "eval_dataset = RFID_Dataset(\n",
    "    eval_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")\n",
    "print(f\"验证集的数据个数: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型组网\n",
    "from torchkeras import summary\n",
    "from model.ClassifyNet.CNNClassifyNet import CNNClassifyNet as ClassifyNet\n",
    "from model.ModelWorker.ClassifyModelWorker import ClassifyModelWorker\n",
    "\n",
    "input_shape=(1,32,12)\n",
    "model=ClassifyNet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=3\n",
    ")\n",
    "\n",
    "model_worker=ClassifyModelWorker(model)\n",
    "\n",
    "print(f\"{input_shape=}\")\n",
    "model_info=summary(model,input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型准备\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=4)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be trained on cuda\n",
      "==============================\n",
      "Epoch [1/5] begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 103/103 [00:01<00:00, 101.37step/s, acc=1, loss=0.000425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2274, Train Acc: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 205/205 [00:00<00:00, 433.42step/s, acc=1, loss=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples:818, Eval Loss: 0.0076, Eval Acc: 0.9988\n",
      "==============================\n",
      "Epoch [2/5] begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 103/103 [00:00<00:00, 145.26step/s, acc=1, loss=2.86e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0331, Train Acc: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 205/205 [00:00<00:00, 492.44step/s, acc=1, loss=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples:818, Eval Loss: 0.0000, Eval Acc: 1.0000\n",
      "==============================\n",
      "Epoch [3/5] begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 103/103 [00:00<00:00, 150.07step/s, acc=1, loss=0.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0072, Train Acc: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 205/205 [00:00<00:00, 512.92step/s, acc=1, loss=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples:818, Eval Loss: 0.0000, Eval Acc: 1.0000\n",
      "==============================\n",
      "Epoch [4/5] begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 103/103 [00:00<00:00, 149.88step/s, acc=1, loss=2.56e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0003, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 205/205 [00:00<00:00, 517.40step/s, acc=1, loss=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples:818, Eval Loss: 0.0000, Eval Acc: 1.0000\n",
      "==============================\n",
      "Epoch [5/5] begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 103/103 [00:00<00:00, 148.93step/s, acc=1, loss=7.55e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0001, Train Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 205/205 [00:00<00:00, 512.00step/s, acc=1, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval samples:818, Eval Loss: 0.0000, Eval Acc: 1.0000\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "\n",
    "model_worker.train(\n",
    "    criterion=loss,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    eval_loader=eval_loader,\n",
    "    epochs=5,\n",
    "    enable_board=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "\n",
    "model_worker.evaluate(\n",
    "    eval_loader=eval_loader,\n",
    "    criterion=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 205/205 [00:00<00:00, 453.23step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MulticlassF1Score': tensor(1., device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "# 评价指标\n",
    "\n",
    "from torchmetrics import MetricCollection, Accuracy, F1Score,ConfusionMatrix\n",
    "\n",
    "res=model_worker.execute_metric(\n",
    "    eval_loader, \n",
    "    MetricCollection([\n",
    "        # Accuracy(task=\"multiclass\", num_classes=10),\n",
    "        F1Score(task=\"multiclass\", num_classes=3),\n",
    "        # ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "    ]),\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model_worker.save('./output/HAR/HAR_robust.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model_worker.load('./output/HAR/HAR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "test_dataset=RFID_Dataset(\n",
    "    r\"./output/improve_v2_robust\",\n",
    "    # r\"data\\RFID\\dataset\\all\",\n",
    "    T=32,\n",
    "    step=1,\n",
    "    # transform=transform,\n",
    ")\n",
    "print(f\"测试集的数据个数: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "model_worker.evaluate(\n",
    "    eval_loader=test_loader,\n",
    "    criterion=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "\n",
    "used_dataset = eval_dataset\n",
    "indexs,inputs,labels = data_utils.select_simple(used_dataset,count=4)\n",
    "preds,acc = model_worker.predict(inputs=inputs,labels=labels)\n",
    "\n",
    "print(f\"{inputs.shape=}\")\n",
    "print(f\"{acc=}\")\n",
    "print(f\"indexs:{indexs}\")\n",
    "print(f\"labels:{labels}\")\n",
    "print(f\"preds :{preds}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
