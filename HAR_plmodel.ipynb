{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人类活动识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "from torchvision import transforms\n",
    "from model.Normalization import *\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    RobustNorm(-7.9, 8.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "from model.RFID_Dataset import RFID_Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "train_dir = r\"data\\RFID_ENV\\dataset\\train\"\n",
    "eval_dir = r\"data\\RFID\\dataset\\eval\"\n",
    "\n",
    "train_dataset = RFID_Dataset(\n",
    "    train_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "eval_dataset = RFID_Dataset(\n",
    "    eval_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")\n",
    "print(f\"验证集的数据个数: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "from model.RFID_Dataset import RFID_Dataset\n",
    "from utils.DatasetUtils import DatasetUtils\n",
    "\n",
    "all_dir=r\"data\\RFID_ENV\\dataset\\all\"\n",
    "\n",
    "all_dataset = RFID_Dataset(\n",
    "    all_dir,\n",
    "    T=12,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "dataset_utils=DatasetUtils()\n",
    "train_dataset, eval_dataset = dataset_utils.split_dataset(all_dataset)\n",
    "\n",
    "\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")\n",
    "print(f\"验证集的数据个数: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型组网\n",
    "from torchkeras import summary\n",
    "from model.ClassifyNet.CNNClassifyNet import CNNClassifyNet as ClassifyNet\n",
    "from model.ModelWorker.ClassifyModelWorker import ClassifyModelWorker\n",
    "\n",
    "input_shape=(1,12,12)\n",
    "model=ClassifyNet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=6\n",
    ")\n",
    "\n",
    "model_worker=ClassifyModelWorker(model)\n",
    "\n",
    "print(f\"{input_shape=}\")\n",
    "model_info=summary(model,input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型准备\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy\n",
    "from model.LightningModel.ClassifyPLModel import ClassifyPLModel\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "metrics= Accuracy(task=\"multiclass\", num_classes=6)\n",
    "\n",
    "\n",
    "# 构建PLModel\n",
    "pl_model = ClassifyPLModel(\n",
    "    model,\n",
    "    loss,\n",
    "    metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=None,\n",
    "    logger=True,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(save_weights_only=True),\n",
    "        EarlyStopping(monitor=\"val/loss\", patience=5),\n",
    "    ],\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    pl_model,\n",
    "    train_loader,\n",
    "    eval_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "\n",
    "model_worker.evaluate(\n",
    "    eval_loader=eval_loader,\n",
    "    criterion=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "\n",
    "from torchmetrics import MetricCollection, Accuracy, F1Score,ConfusionMatrix\n",
    "from utils.ConfigUtils import get_classes\n",
    "\n",
    "classes=get_classes(r\"data\\RFID_ENV\\data.yml\")\n",
    "num_classes = len(classes)\n",
    "\n",
    "res=model_worker.execute_metric(\n",
    "    train_loader, \n",
    "    MetricCollection([\n",
    "        Accuracy(task=\"multiclass\", num_classes=num_classes),\n",
    "        F1Score(task=\"multiclass\", num_classes=num_classes),\n",
    "        ConfusionMatrix(task=\"multiclass\", num_classes=num_classes,normalize=\"true\")\n",
    "    ]),\n",
    ")\n",
    "\n",
    "for item in res.items():\n",
    "    print(f\"{item[0]}:\\n\\t {item[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DataUtils.Visualization import plot_confusion_matrix\n",
    "\n",
    "confusion_matrix=res[\"MulticlassConfusionMatrix\"].cpu()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    class_names=classes.values(),\n",
    "    is_percentage=True,\n",
    "    title=\"train confusion matrix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model_worker.save('./output/HAR_ENV/HAR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model_worker.load('./output/HAR_ENV/HAR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "test_dataset=RFID_Dataset(\n",
    "    r\"./output/merge\",\n",
    "    T=32,\n",
    "    step=32,\n",
    "    # transform=transform,\n",
    ")\n",
    "print(f\"测试集的数据个数: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "model_worker.evaluate(\n",
    "    eval_loader=test_loader,\n",
    "    criterion=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "\n",
    "used_dataset = eval_dataset\n",
    "indexs,inputs,labels = dataset_utils.select_simple(used_dataset,count=4)\n",
    "preds,acc = model_worker.predict(inputs=inputs,labels=labels)\n",
    "\n",
    "print(f\"{inputs.shape=}\")\n",
    "print(f\"{acc=}\")\n",
    "print(f\"indexs:{indexs}\")\n",
    "print(f\"labels:{labels}\")\n",
    "print(f\"preds :{preds}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
