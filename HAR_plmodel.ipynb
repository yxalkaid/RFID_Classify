{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人类活动识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载类别信息\n",
    "\n",
    "from utils.ConfigUtils import get_classes\n",
    "\n",
    "classes=list(get_classes(r\"data\\RFID_multi_628\\data.yml\").values())\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "from torchvision import transforms\n",
    "from model.Normalization import *\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    RobustNorm(-68.0, 68.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "from model.RFID_Dataset import RFID_Dataset\n",
    "\n",
    "train_dir = r\"data\\RFID_multi_628\\dataset\\train\"\n",
    "eval_dir = r\"data\\RFID_multi_628\\dataset\\eval\"\n",
    "generate_dir=\"./output/base\"\n",
    "\n",
    "train_dataset = RFID_Dataset(\n",
    "    train_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    num_channels=3,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "eval_dataset = RFID_Dataset(\n",
    "    eval_dir,\n",
    "    T=32,\n",
    "    step=1,\n",
    "    num_channels=3,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "generate_dataset = RFID_Dataset(\n",
    "    generate_dir,\n",
    "    T=32,\n",
    "    step=32,\n",
    "    num_channels=3,\n",
    "    transform=transforms.Compose([\n",
    "    # RobustNorm(-1.0, 1.0),\n",
    "]),\n",
    ")\n",
    "\n",
    "# train_dataset=generate_dataset\n",
    "\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")\n",
    "print(f\"验证集的数据个数: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "from model.RFID_Dataset import RFID_Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dir_group = [\n",
    "    r\"data\\RFID_multi_628\\dataset\\person\\hyx\",\n",
    "    r\"data\\RFID_multi_628\\dataset\\person\\lrf\",\n",
    "    r\"data\\RFID_multi_628\\dataset\\person\\ljl\",\n",
    "    r\"data\\RFID_multi_628\\dataset\\person\\xjy\",\n",
    "    r\"data\\RFID_multi_628\\dataset\\person\\hjx\",\n",
    "]\n",
    "\n",
    "dataset_group=[]\n",
    "for dir in dir_group:\n",
    "    dataset_group.append(RFID_Dataset(\n",
    "        dir,\n",
    "        T=32,\n",
    "        step=1,\n",
    "        num_channels=3,\n",
    "        transform=transform,\n",
    "    ))\n",
    "\n",
    "person_count=3\n",
    "train_dataset=ConcatDataset(dataset_group[:person_count])\n",
    "eval_dataset=ConcatDataset(dataset_group[person_count:])\n",
    "\n",
    "print(f\"训练集的数据个数: {len(train_dataset)}\")\n",
    "print(f\"验证集的数据个数: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型组网\n",
    "# from model.ClassifyNet.MixedMemoryNet import MixedMemoryNet as ClassifyNet\n",
    "from model.ClassifyNet.CNNClassifyNet import CNNClassifyNet as ClassifyNet\n",
    "from model.ModelWorker.ClassifyModelWorker import ClassifyModelWorker\n",
    "from torchkeras import summary\n",
    "\n",
    "input_shape=(3,32,12)\n",
    "model=ClassifyNet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "model_worker=ClassifyModelWorker(model)\n",
    "\n",
    "print(f\"{input_shape=}\")\n",
    "model_info=summary(model,input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型准备\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy,F1Score\n",
    "from model.LightningModel.ClassifyPLModel import ClassifyPLModel\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "metrics= {\n",
    "    \"F1Score\":F1Score(task=\"multiclass\", num_classes=num_classes)\n",
    "}\n",
    "\n",
    "pl_model = ClassifyPLModel(\n",
    "    model,\n",
    "    loss,\n",
    "    metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建PLTrainer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    min_epochs=5,\n",
    "    logger=True,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(save_weights_only=True),\n",
    "        # EarlyStopping(monitor=\"val/loss\", patience=5),\n",
    "        EarlyStopping(monitor=\"val/F1Score\", patience=5,mode=\"max\"),\n",
    "    ],\n",
    "    default_root_dir=\"./output/HAR\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "\n",
    "trainer.fit(\n",
    "    pl_model,\n",
    "    train_loader,\n",
    "    eval_loader,\n",
    ")\n",
    "best_model_path=trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载PLModel\n",
    "\n",
    "best_model_path=r\"output\\HAR\\lightning_logs\\version_7\\checkpoints\\epoch=99-step=6100.ckpt\"\n",
    "pl_model=ClassifyPLModel.load_from_checkpoint(\n",
    "    best_model_path, \n",
    "    model=model, \n",
    "    criterion=loss,\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=\"./output/base\"\n",
    "test_dataset=eval_dataset = RFID_Dataset(\n",
    "    test_dir,\n",
    "    T=32,\n",
    "    step=32,\n",
    "    num_channels=3,\n",
    "    # transform=transform,\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)\n",
    "\n",
    "print(f\"测试集的数据个数: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "\n",
    "trainer.validate(\n",
    "    pl_model,\n",
    "    test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "\n",
    "from torchmetrics import MetricCollection, Accuracy, F1Score,ConfusionMatrix\n",
    "\n",
    "used_dataset = \"test_dataset\"\n",
    "dataset_group={\n",
    "    \"train_dataset\": train_loader,\n",
    "    \"eval_dataset\": eval_loader,\n",
    "    \"test_dataset\": test_loader,\n",
    "}\n",
    "res=model_worker.execute_metric(\n",
    "    dataset_group[used_dataset],\n",
    "    MetricCollection([\n",
    "        # Accuracy(task=\"multiclass\", num_classes=num_classes),\n",
    "        F1Score(task=\"multiclass\", num_classes=num_classes),\n",
    "        ConfusionMatrix(task=\"multiclass\", num_classes=num_classes,normalize=\"true\")\n",
    "    ]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示混淆矩阵\n",
    "\n",
    "from utils.DataUtils.Visualization import plot_confusion_matrix\n",
    "\n",
    "title=f\"{used_dataset}, F1Score: {res['MulticlassF1Score']:.6f}\"\n",
    "confusion_matrix=res[\"MulticlassConfusionMatrix\"].cpu()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    class_names=classes,\n",
    "    is_percentage=True,\n",
    "    title=title,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model_worker.save('./output/HAR/HAR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model_worker.load('./output/HAR/HAR.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "from utils.DatasetUtils import DatasetUtils\n",
    "\n",
    "used_dataset = eval_dataset\n",
    "indexs,inputs,labels = DatasetUtils().select_simple(used_dataset,count=4)\n",
    "preds,acc = model_worker.predict(inputs=inputs,labels=labels)\n",
    "\n",
    "print(f\"{inputs.shape=}\")\n",
    "print(f\"{acc=}\")\n",
    "print(f\"indexs:{indexs}\")\n",
    "print(f\"labels:{labels}\")\n",
    "print(f\"preds :{preds}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
